#!/usr/bin/env python3
# Original: Copyright (c) 2024 ZAI Organization (Apache-2.0)
# Modified: Copyright (C) 2025 PhoneAgent Contributors (AGPL-3.0)
# Based on: https://github.com/zai-org/Open-AutoGLM

"""Model client for AI inference using OpenAI-compatible API."""

import json
from dataclasses import dataclass, field
from typing import Any

from openai import OpenAI


@dataclass
class ModelConfig:
    """Configuration for the AI model."""

    base_url: str = "http://localhost:8000/v1"
    api_key: str = "EMPTY"
    model_name: str = "autoglm-phone-9b"
    max_tokens: int = 3000
    temperature: float = 0.0
    top_p: float = 0.85
    frequency_penalty: float = 0.2
    timeout: float = 120.0  # ğŸ†• LLMè¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤120ç§’
    extra_body: dict[str, Any] = field(default_factory=lambda: {"skip_special_tokens": False})


@dataclass
class ModelResponse:
    """Response from the AI model."""

    thinking: str
    action: str
    raw_content: str
    usage: dict[str, Any] | None = None  # Token usage info


class ModelClient:
    """
    Client for interacting with OpenAI-compatible vision-language models.

    Args:
        config: Model configuration.
    """

    def __init__(self, config: ModelConfig | None = None):
        self.config = config or ModelConfig()
        # ğŸ†• é…ç½®è¶…æ—¶æ—¶é—´ï¼Œé˜²æ­¢ LLM è°ƒç”¨æ°¸ä¹…æŒ‚èµ·
        self.client = OpenAI(
            base_url=self.config.base_url,
            api_key=self.config.api_key,
            timeout=self.config.timeout,
        )

    def request(self, messages: list[dict[str, Any]]) -> ModelResponse:
        """
        Send a request to the model.

        Args:
            messages: List of message dictionaries in OpenAI format.

        Returns:
            ModelResponse containing thinking and action.

        Raises:
            ValueError: If the response cannot be parsed.
        """
        # æ„å»ºè¯·æ±‚å‚æ•°
        request_params = {
            "messages": messages,
            "model": self.config.model_name,
            "max_tokens": self.config.max_tokens,
            "temperature": self.config.temperature,
            "top_p": self.config.top_p,
        }

        # åªæœ‰å½“ frequency_penalty ä¸ä¸º 0 æ—¶æ‰æ·»åŠ ï¼ˆå…¼å®¹æ™ºè°±ç­‰ APIï¼‰
        if self.config.frequency_penalty != 0.0:
            request_params["frequency_penalty"] = self.config.frequency_penalty

        # åªæœ‰å½“ extra_body ä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ 
        if self.config.extra_body:
            request_params["extra_body"] = self.config.extra_body

        response = self.client.chat.completions.create(**request_params)

        raw_content = response.choices[0].message.content

        # Parse thinking and action from response
        thinking, action = self._parse_response(raw_content)

        # Extract token usage (æ”¯æŒæ ‡å‡†OpenAIæ ¼å¼å’Œæ™ºè°±AIæ‰©å±•æ ¼å¼)
        usage = None
        if hasattr(response, "usage") and response.usage:
            usage = {
                "prompt_tokens": getattr(response.usage, "prompt_tokens", 0),
                "completion_tokens": getattr(response.usage, "completion_tokens", 0),
                "total_tokens": getattr(response.usage, "total_tokens", 0),
            }

            # æ™ºè°±AIæ·±åº¦æ€è€ƒæ¨¡å‹é¢å¤–è¿”å›å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            # completion_tokens_details: {"reasoning_tokens": xxx, "accepted_prediction_tokens": xxx, "rejected_prediction_tokens": xxx}
            if hasattr(response.usage, "completion_tokens_details"):
                details = response.usage.completion_tokens_details
                usage["completion_tokens_details"] = {
                    "reasoning_tokens": getattr(details, "reasoning_tokens", 0),
                    "accepted_prediction_tokens": getattr(details, "accepted_prediction_tokens", 0),
                    "rejected_prediction_tokens": getattr(details, "rejected_prediction_tokens", 0),
                }

        return ModelResponse(thinking=thinking, action=action, raw_content=raw_content, usage=usage)

    def request_json(
        self, messages: list[dict[str, Any]], temperature: float | None = None
    ) -> ModelResponse:
        """
        è¯·æ±‚JSONæ ¼å¼å“åº”ï¼ˆç”¨äºXML Kernelç­‰åœºæ™¯ï¼‰

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°ï¼ˆå¯é€‰ï¼Œè¦†ç›–é…ç½®ï¼‰

        Returns:
            ModelResponseï¼Œå…¶ä¸­ raw_content ä¸º JSON å­—ç¬¦ä¸²

        Raises:
            ValueError: å¦‚æœå“åº”æ— æ³•è§£æ

        Example:
            >>> client = ModelClient(config)
            >>> response = client.request_json([
            ...     {"role": "system", "content": "You are a helpful assistant."},
            ...     {"role": "user", "content": "è¿”å›JSON: {\"action\": \"tap\", \"x\": 100}"}
            ... ])
            >>> data = json.loads(response.raw_content)
        """
        # æ„å»ºè¯·æ±‚å‚æ•°
        request_params = {
            "messages": messages,
            "model": self.config.model_name,
            "max_tokens": self.config.max_tokens,
            "temperature": temperature if temperature is not None else self.config.temperature,
            "top_p": self.config.top_p,
            "response_format": {"type": "json_object"},  # ğŸ†• å¼ºåˆ¶JSONè¾“å‡º
        }

        # åªæœ‰å½“ frequency_penalty ä¸ä¸º 0 æ—¶æ‰æ·»åŠ 
        if self.config.frequency_penalty != 0.0:
            request_params["frequency_penalty"] = self.config.frequency_penalty

        # åªæœ‰å½“ extra_body ä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ 
        if self.config.extra_body:
            request_params["extra_body"] = self.config.extra_body

        response = self.client.chat.completions.create(**request_params)

        raw_content = response.choices[0].message.content

        # Extract token usage
        usage = None
        if hasattr(response, "usage") and response.usage:
            usage = {
                "prompt_tokens": getattr(response.usage, "prompt_tokens", 0),
                "completion_tokens": getattr(response.usage, "completion_tokens", 0),
                "total_tokens": getattr(response.usage, "total_tokens", 0),
            }

            # æ™ºè°±AIæ·±åº¦æ€è€ƒæ¨¡å‹é¢å¤–è¿”å›å­—æ®µ
            if hasattr(response.usage, "completion_tokens_details"):
                details = response.usage.completion_tokens_details
                usage["completion_tokens_details"] = {
                    "reasoning_tokens": getattr(details, "reasoning_tokens", 0),
                    "accepted_prediction_tokens": getattr(details, "accepted_prediction_tokens", 0),
                    "rejected_prediction_tokens": getattr(details, "rejected_prediction_tokens", 0),
                }

        # JSONæ¨¡å¼ä¸‹ï¼Œthinkingä¸ºç©ºï¼Œæ•´ä¸ªJSONä½œä¸ºaction
        return ModelResponse(thinking="", action=raw_content, raw_content=raw_content, usage=usage)

    def _parse_response(self, content: str) -> tuple[str, str]:
        """
        Parse the model response into thinking and action parts.

        æ”¯æŒçš„æ¨¡å‹å’Œæ ¼å¼ï¼š
        - autoglm-phone (å®˜æ–¹æ¨è): <think>...</think><answer>...</answer>
        - glm-4.1v-thinking-flash (å…è´¹): {think}...{action}... æˆ– boxæ ¼å¼
        - glm-4.1v-thinking-flashx (é«˜å¹¶å‘): åŒthinking-flash
        - é€šç”¨å…œåº•: JSONæ ¼å¼ æˆ– çº¯æ–‡æœ¬æå–do(...)

        æ ¼å¼ä¼˜å…ˆçº§ï¼š
        1. AutoGLM æ ‡å‡†æ ¼å¼ï¼ˆæœ€ä¼˜å…ˆï¼‰
        2. JSON æ ¼å¼ï¼ˆæ˜ç¡®ã€æ˜“è°ƒè¯•ï¼‰
        3. GLM-Thinking å¤šè¡Œæ ¼å¼
        4. GLM-Thinking Boxæ ¼å¼
        5. çº¯æ–‡æœ¬æå–ï¼ˆå…œåº•ï¼‰

        Args:
            content: Raw response content.

        Returns:
            Tuple of (thinking, action).
        """
        import json
        import re

        # æ ¼å¼1: AutoGLM æ ‡å‡†æ ¼å¼ <think>...</think><answer>...</answer>
        if "<answer>" in content:
            parts = content.split("<answer>", 1)
            thinking = parts[0].replace("<think>", "").replace("</think>", "").strip()
            action = parts[1].replace("</answer>", "").strip()
            return thinking, action

        # æ ¼å¼2: JSON æ ¼å¼ {"think": "...", "action": "..."}
        if content.strip().startswith("{") and '"think"' in content and '"action"' in content:
            try:
                # å°è¯•è§£æ JSON
                data = json.loads(content.strip())
                if isinstance(data, dict) and "think" in data and "action" in data:
                    return str(data["think"]), str(data["action"])
            except json.JSONDecodeError:
                # JSON è§£æå¤±è´¥ï¼Œå°è¯•ç”¨æ­£åˆ™æå–ï¼ˆå¤„ç†åµŒå¥—å¼•å·é—®é¢˜ï¼‰
                # æå– think å­—æ®µï¼ˆåœ¨é€—å·ä¹‹å‰ï¼‰
                think_match = re.search(r'"think"\s*:\s*"([^"]*(?:"[^"]*"[^"]*)*)"', content)
                if not think_match:
                    # å°è¯•æ›´å®½æ¾çš„åŒ¹é…
                    think_match = re.search(
                        r'"think"\s*:\s*"(.*?)",\s*"action"', content, re.DOTALL
                    )

                # æå– action å­—æ®µï¼ˆå¯èƒ½åŒ…å«åµŒå¥—å¼•å·ï¼‰
                # åŒ¹é… "action": "do(action="xxx")" æˆ– "action": "do(...)"
                action_match = re.search(r'"action"\s*:\s*"(do\([^)]+\))"', content)

                if think_match and action_match:
                    thinking = think_match.group(1).strip()
                    action = action_match.group(1).strip()
                    return thinking, action

        # æ ¼å¼3: GLM-4.1V-Thinking æ ¼å¼ {think}...{action}...
        # åŒ…æ‹¬æ¢è¡Œçš„æƒ…å†µï¼š{think}...\n{action}...
        if "{think}" in content and "{action}" in content:
            think_match = re.search(r"\{think\}(.*?)\{action\}", content, re.DOTALL)
            if think_match:
                thinking = think_match.group(1).strip()
                # æå– {action} åé¢çš„ do(...) æŒ‡ä»¤
                action_section = content.split("{action}")[1]
                # åœ¨ action section ä¸­æ‰¾ do(...) æˆ– finish(...)
                action_match = re.search(r"((?:do|finish)\([^)]+\))", action_section)
                action = (
                    action_match.group(1).strip()
                    if action_match
                    else action_section.split("\n")[0].strip()
                )
                # ç§»é™¤å¯èƒ½çš„æ³¨é‡Š
                action = re.sub(r"//[^\n]*", "", action).strip()
                return thinking, action

        # æ ¼å¼3: GLM-4.1V-Thinking æ ¼å¼ {think>...}<|begin_of_box|>...<|end_of_box|>
        if "{think>" in content or "{think}" in content:
            # æå– thinking éƒ¨åˆ†
            think_match = re.search(r"\{think[>]?(.*?)\}", content, re.DOTALL)
            thinking = think_match.group(1).strip() if think_match else ""

            # æå– action éƒ¨åˆ†ï¼ˆåœ¨ box æ ‡è®°å†…æˆ– think åé¢ï¼‰
            box_match = re.search(r"<\|begin_of_box\|\>(.*?)<\|end_of_box\|\>", content, re.DOTALL)
            if box_match:
                action = box_match.group(1).strip()
                # ç§»é™¤å¯èƒ½çš„ {action} å‰ç¼€
                action = re.sub(r"^\{action\}", "", action).strip()
                # ç§»é™¤æ³¨é‡Šï¼ˆ// å¼€å¤´çš„è¡Œï¼‰
                action = re.sub(r"//[^\n]*", "", action).strip()
            else:
                # å¦‚æœæ²¡æœ‰ box æ ‡è®°ï¼Œå¯»æ‰¾ {action}... æ ¼å¼
                action_match = re.search(r"\{action\}(.*?)(?:\n//|$)", content, re.DOTALL)
                if action_match:
                    action = action_match.group(1).strip()
                else:
                    # å– think åé¢çš„å†…å®¹
                    action_match = re.search(r"\{think[>]?.*?\}(.*)$", content, re.DOTALL)
                    action = action_match.group(1).strip() if action_match else ""
                    # ç§»é™¤æ³¨é‡Š
                    action = re.sub(r"//[^\n]*", "", action).strip()

            return thinking, action

        # æ ¼å¼4: GLM-4.1V è¾“å‡º <think>... ä½†æ²¡æœ‰é—­åˆæ ‡ç­¾å’Œ <answer>
        # è¿™ç§æƒ…å†µä¸‹ï¼Œthinking å¤ªé•¿è¢«æˆªæ–­äº†ï¼Œç›´æ¥è¿”å›ç©º thinking å’ŒåŸå†…å®¹ä½œä¸º action
        # å› ä¸º parse_action ä¼šå¤±è´¥ï¼Œagent ä¼šè‡ªåŠ¨è°ƒç”¨ finish
        if "<think>" in content:
            # å°è¯•æå–ä¸€ä¸ªåˆç†çš„ actionï¼ˆå¯èƒ½åœ¨æœ€åï¼‰
            # æŸ¥æ‰¾ do(...) æˆ– finish(...) æ¨¡å¼
            action_pattern = r"((?:do|finish)\([^)]+\))"
            matches = re.findall(action_pattern, content)
            if matches:
                # å–æœ€åä¸€ä¸ªåŒ¹é…çš„ action
                action = matches[-1]
                # thinking æ˜¯ action ä¹‹å‰çš„å†…å®¹
                idx = content.rfind(action)
                thinking_text = content[:idx].replace("<think>", "").replace("</think>", "").strip()
                # é™åˆ¶ thinking é•¿åº¦é¿å…å¤ªé•¿
                thinking = thinking_text[-500:] if len(thinking_text) > 500 else thinking_text
                return thinking, action

        # é»˜è®¤ï¼šå°è¯•ä»ä»»ä½•æ ¼å¼ä¸­æå– do(...) æˆ– finish(...) æŒ‡ä»¤
        # è¿™æ˜¯æœ€åçš„å…œåº•æ–¹æ¡ˆï¼Œç”¨äºå¤„ç†å„ç§å¥‡æ€ªçš„è¾“å‡ºæ ¼å¼

        # ä½¿ç”¨æ­£åˆ™æå–æ‰€æœ‰ do(...) æˆ– finish(...) æ¨¡å¼
        # æ”¯æŒåµŒå¥—æ‹¬å·å’Œå¼•å·
        all_matches = []

        # æ–¹æ³•1: æ‰¾åˆ°æ‰€æœ‰å®Œæ•´çš„ do(...) æˆ– finish(...) è°ƒç”¨
        # æ”¹è¿›çš„æ­£åˆ™ï¼šåŒ¹é… do( æˆ– finish( åé¢çš„å†…å®¹ï¼Œç›´åˆ°æ‰¾åˆ°åŒ¹é…çš„ )
        # æ”¯æŒå¼•å·å’ŒåµŒå¥—
        for match in re.finditer(r"((?:do|finish)\s*\([^()]*(?:\([^()]*\)[^()]*)*\))", content):
            all_matches.append(match.group(1))

        if all_matches:
            # å–æœ€åä¸€ä¸ªåŒ¹é…ï¼ˆé€šå¸¸æ˜¯æœ€ç»ˆçš„actionæŒ‡ä»¤ï¼‰
            action = all_matches[-1].strip()
            # thinking æ˜¯ action ä¹‹å‰çš„å†…å®¹
            idx = content.rfind(action)
            thinking = content[:idx] if idx > 0 else ""
            # æ¸…ç† thinking ä¸­çš„å„ç§æ ‡è®°
            thinking = re.sub(
                r'\{think[>]?\}?|\{\/think\}?|\</think\>|\{action\}|\<\|begin_of_box\|\>|\<\|end_of_box\|\>|//[^\n]*|"think"\s*:|"action"\s*:',
                "",
                thinking,
            ).strip()
            thinking = re.sub(r'^\{+|\}+$|^"+|"+$', "", thinking).strip()
            return thinking, action

        # å®Œå…¨æ— æ³•è§£æï¼Œè¿”å›ç©ºthinkingå’ŒåŸå†…å®¹ï¼ˆä¼šå¯¼è‡´ parse_action å¤±è´¥ï¼‰
        return "", content


class MessageBuilder:
    """Helper class for building conversation messages."""

    @staticmethod
    def create_system_message(content: str) -> dict[str, Any]:
        """Create a system message."""
        return {"role": "system", "content": content}

    @staticmethod
    def create_user_message(text: str, image_base64: str | None = None) -> dict[str, Any]:
        """
        Create a user message with optional image.

        Args:
            text: Text content.
            image_base64: Optional base64-encoded image.

        Returns:
            Message dictionary.
        """
        content = []

        if image_base64:
            content.append(
                {
                    "type": "image_url",
                    "image_url": {"url": f"data:image/png;base64,{image_base64}"},
                }
            )

        content.append({"type": "text", "text": text})

        return {"role": "user", "content": content}

    @staticmethod
    def create_assistant_message(content: str) -> dict[str, Any]:
        """Create an assistant message."""
        return {"role": "assistant", "content": content}

    @staticmethod
    def remove_images_from_message(message: dict[str, Any]) -> dict[str, Any]:
        """
        Remove image content from a message to save context space.

        Args:
            message: Message dictionary.

        Returns:
            Message with images removed.
        """
        if isinstance(message.get("content"), list):
            message["content"] = [item for item in message["content"] if item.get("type") == "text"]
        return message

    @staticmethod
    def build_screen_info(current_app: str, **extra_info) -> str:
        """
        Build screen info string for the model.

        Args:
            current_app: Current app name.
            **extra_info: Additional info to include.

        Returns:
            JSON string with screen info.
        """
        info = {"current_app": current_app, **extra_info}
        return json.dumps(info, ensure_ascii=False)
