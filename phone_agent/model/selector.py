#!/usr/bin/env python3
# Copyright (C) 2025 PhoneAgent Contributors
# Licensed under AGPL-3.0

"""
æ¨¡å‹é€‰æ‹©ç­–ç•¥ç®¡ç†å™¨

æ ¹æ®æ‰§è¡Œå†…æ ¸ï¼ˆXML/Visionï¼‰è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹ï¼š
- XML Kernel â†’ GLM-4-1V-Thinking-Flashï¼ˆ64kä¸Šä¸‹æ–‡ï¼Œå…è´¹ï¼Œé€‚åˆé•¿ä»»åŠ¡ï¼‰
- Vision Kernel â†’ AutoGLM-Phoneï¼ˆå®˜æ–¹æ¨èï¼Œé’ˆå¯¹è§†è§‰ä»»åŠ¡ä¼˜åŒ–ï¼‰

æ”¯æŒç¯å¢ƒå˜é‡é…ç½®å’Œè¿è¡Œæ—¶åŠ¨æ€åˆ‡æ¢ã€‚
"""

import logging
import os
from dataclasses import dataclass
from enum import Enum
from typing import Dict, Optional

logger = logging.getLogger(__name__)


class KernelType(Enum):
    """å†…æ ¸ç±»å‹"""

    XML = "xml"  # XMLå†…æ ¸ï¼ˆåŸºäºUIæ ‘ï¼‰
    VISION = "vision"  # Visionå†…æ ¸ï¼ˆåŸºäºæˆªå›¾ï¼‰
    PLANNING = "planning"  # è§„åˆ’æ¨¡å¼
    AUTO = "auto"  # è‡ªåŠ¨é€‰æ‹©


@dataclass
class ModelPreset:
    """æ¨¡å‹é¢„è®¾é…ç½®"""

    model_name: str
    description: str
    context_length: int
    free: bool
    recommended_for: list[str]

    def __str__(self):
        free_tag = "ğŸ†“å…è´¹" if self.free else "ğŸ’°ä»˜è´¹"
        return f"{self.model_name} ({free_tag}, {self.context_length//1000}kä¸Šä¸‹æ–‡)"


# ============================================
# å¯ç”¨æ¨¡å‹é¢„è®¾
# ============================================

AVAILABLE_MODELS = {
    # ============================================
    # AutoGLM å®˜æ–¹æ¨¡å‹
    # ============================================
    "autoglm-phone": ModelPreset(
        model_name="autoglm-phone",
        description="AutoGLMå®˜æ–¹Phoneæ¨¡å‹ï¼Œé’ˆå¯¹æ‰‹æœºè‡ªåŠ¨åŒ–ä¼˜åŒ–",
        context_length=25_480,  # æœªå®˜æ–¹æŠ«éœ²ï¼Œä¿å®ˆä¼°è®¡
        free=True,
        recommended_for=["vision"],
    ),
    # ============================================
    # GLM-4.6v ç³»åˆ—ï¼ˆæœ€æ–°æ——èˆ°è§†è§‰æ¨¡å‹ï¼‰
    # ============================================
    "glm-4.6v": ModelPreset(
        model_name="glm-4.6v",
        description="GLM-4.6è§†è§‰æ——èˆ°æ¨¡å‹ï¼Œæœ€å¼ºè§†è§‰ç†è§£èƒ½åŠ›ï¼ˆä»˜è´¹ï¼‰",
        context_length=8_000,
        free=False,
        recommended_for=["vision", "planning"],
    ),
    "glm-4.6v-flash": ModelPreset(
        model_name="glm-4.6v-flash",
        description="GLM-4.6è§†è§‰Flashç‰ˆï¼Œå…è´¹ï¼Œé«˜æ€§ä»·æ¯”",
        context_length=8_000,
        free=True,
        recommended_for=["vision", "planning"],
    ),
    "glm-4.6v-flashx": ModelPreset(
        model_name="glm-4.6v-flashx",
        description="GLM-4.6è§†è§‰FlashXç‰ˆï¼Œæé€Ÿå“åº”ï¼ˆä»˜è´¹ï¼‰",
        context_length=8_000,
        free=False,
        recommended_for=["vision"],
    ),
    # ============================================
    # GLM-4.1v ç³»åˆ—ï¼ˆæ—§ç‰ˆï¼Œä¿ç•™ç”¨äºå…¼å®¹ï¼‰
    # ============================================
    "glm-4.1v-thinking-flash": ModelPreset(
        model_name="glm-4.1v-thinking-flash",
        description="GLM-4.1è§†è§‰æ¨ç†æ¨¡å‹Flashç‰ˆï¼Œå…è´¹ï¼Œ64kä¸Šä¸‹æ–‡",
        context_length=64_000,
        free=True,
        recommended_for=["xml", "planning", "auto"],
    ),
}


# ============================================
# é»˜è®¤ç­–ç•¥é…ç½®
# ============================================

DEFAULT_MODEL_STRATEGY = {
    # Warning: XMLå†…æ ¸å·²åºŸå¼ƒï¼Œé»˜è®¤fallbackåˆ°vision
    KernelType.XML: "autoglm-phone",
    # Visionå†…æ ¸ä½¿ç”¨AutoGLMå®˜æ–¹Phoneæ¨¡å‹ï¼ˆæ¨èï¼‰
    KernelType.VISION: "autoglm-phone",
    # è§„åˆ’æ¨¡å¼ä½¿ç”¨autoglm-phoneï¼ˆé’ˆå¯¹æ‰‹æœºä¼˜åŒ–ï¼‰
    KernelType.PLANNING: "autoglm-phone",
    # è‡ªåŠ¨æ¨¡å¼ä½¿ç”¨autoglm-phone
    KernelType.AUTO: "autoglm-phone",
}


class ModelSelector:
    """
    æ¨¡å‹é€‰æ‹©å™¨

    æ ¹æ®æ‰§è¡Œå†…æ ¸ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å‹ã€‚
    æ”¯æŒç¯å¢ƒå˜é‡é…ç½®è¦†ç›–é»˜è®¤ç­–ç•¥ã€‚

    Environment Variables:
        VISION_KERNEL_MODEL: Visionå†…æ ¸ä½¿ç”¨çš„æ¨¡å‹ï¼ˆé»˜è®¤: glm-4.6v-flashï¼‰
        PLANNING_KERNEL_MODEL: è§„åˆ’æ¨¡å¼ä½¿ç”¨çš„æ¨¡å‹ï¼ˆé»˜è®¤: glm-4.6v-flashï¼‰
        CUSTOM_MODEL_NAME: å¼ºåˆ¶æ‰€æœ‰æ¨¡å¼ä½¿ç”¨åŒä¸€æ¨¡å‹ï¼ˆæ¨èï¼šglm-4.6v, glm-4.6v-flash, glm-4.6v-flashxï¼‰

    Example:
        >>> selector = ModelSelector()
        >>> model = selector.select_model(KernelType.XML)
        >>> print(model)  # glm-4.1v-thinking-flash

        >>> model = selector.select_model(KernelType.VISION)
        >>> print(model)  # autoglm-phone
    """

    def __init__(self):
        self.strategy = self._load_strategy()
        self._log_strategy()

    def _load_strategy(self) -> Dict[KernelType, str]:
        """ä»ç¯å¢ƒå˜é‡åŠ è½½ç­–ç•¥ï¼ˆæ”¯æŒå¤šå¹³å°ï¼‰"""
        strategy = DEFAULT_MODEL_STRATEGY.copy()

        # ä¼˜å…ˆæ£€æŸ¥ MODEL_PROVIDER å’Œ CUSTOM_MODEL_NAME
        # å¦‚æœè®¾ç½®äº†è‡ªå®šä¹‰æ¨¡å‹ï¼Œæ‰€æœ‰å†…æ ¸éƒ½ä½¿ç”¨å®ƒ
        custom_model = os.getenv("CUSTOM_MODEL_NAME")
        if custom_model:
            logger.info(f"ğŸŒ ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹: {custom_model} (æ‰€æœ‰å†…æ ¸)")
            return {
                KernelType.XML: custom_model,
                KernelType.VISION: custom_model,
                KernelType.PLANNING: custom_model,
                KernelType.AUTO: custom_model,
            }

        # æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨å•ä¸€æ¨¡å‹ï¼ˆå‘åå…¼å®¹ï¼‰
        force_model = os.getenv("FORCE_SINGLE_MODEL")
        if force_model:
            logger.info(f"ğŸ”’ å¼ºåˆ¶æ‰€æœ‰å†…æ ¸ä½¿ç”¨æ¨¡å‹: {force_model}")
            for kernel_type in KernelType:
                strategy[kernel_type] = force_model
            return strategy

        # ä»ç¯å¢ƒå˜é‡åŠ è½½å„å†…æ ¸çš„æ¨¡å‹é…ç½®
        xml_model = os.getenv("XML_KERNEL_MODEL")
        if xml_model:
            strategy[KernelType.XML] = xml_model
            logger.info(f"XMLå†…æ ¸æ¨¡å‹ï¼ˆç¯å¢ƒå˜é‡ï¼‰: {xml_model}")

        vision_model = os.getenv("VISION_KERNEL_MODEL")
        if vision_model:
            strategy[KernelType.VISION] = vision_model
            logger.info(f"Visionå†…æ ¸æ¨¡å‹ï¼ˆç¯å¢ƒå˜é‡ï¼‰: {vision_model}")

        planning_model = os.getenv("PLANNING_KERNEL_MODEL")
        if planning_model:
            strategy[KernelType.PLANNING] = planning_model
            logger.info(f"è§„åˆ’æ¨¡å¼æ¨¡å‹ï¼ˆç¯å¢ƒå˜é‡ï¼‰: {planning_model}")

        return strategy

    def _log_strategy(self):
        """æ‰“å°å½“å‰ç­–ç•¥"""
        logger.info("ğŸ“‹ æ¨¡å‹é€‰æ‹©ç­–ç•¥:")
        for kernel_type, model_name in self.strategy.items():
            preset = AVAILABLE_MODELS.get(model_name)
            if preset:
                logger.info(f"  â€¢ {kernel_type.value:12} â†’ {preset}")
            else:
                logger.warning(f"  â€¢ {kernel_type.value:12} â†’ {model_name} (æœªçŸ¥æ¨¡å‹)")

    def select_model(self, kernel_type: KernelType, override_model: Optional[str] = None) -> str:
        """
        é€‰æ‹©æ¨¡å‹

        Args:
            kernel_type: å†…æ ¸ç±»å‹
            override_model: å¼ºåˆ¶æŒ‡å®šçš„æ¨¡å‹ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰

        Returns:
            æ¨¡å‹åç§°
        """
        # ä¼˜å…ˆä½¿ç”¨å¼ºåˆ¶æŒ‡å®šçš„æ¨¡å‹
        if override_model:
            logger.info(f"ğŸ¯ ä½¿ç”¨å¼ºåˆ¶æŒ‡å®šæ¨¡å‹: {override_model}")
            return override_model

        # ä½¿ç”¨ç­–ç•¥é€‰æ‹©
        model_name = self.strategy.get(kernel_type, DEFAULT_MODEL_STRATEGY[KernelType.AUTO])

        preset = AVAILABLE_MODELS.get(model_name)
        if preset:
            logger.debug(f"{kernel_type.value} å†…æ ¸ â†’ {preset}")
        else:
            logger.warning(f"æœªçŸ¥æ¨¡å‹: {model_name}")

        return model_name

    def get_model_info(self, model_name: str) -> Optional[ModelPreset]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return AVAILABLE_MODELS.get(model_name)

    def list_available_models(self) -> Dict[str, ModelPreset]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        return AVAILABLE_MODELS.copy()

    def validate_model(self, model_name: str) -> bool:
        """éªŒè¯æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        return model_name in AVAILABLE_MODELS


# ============================================
# å…¨å±€å•ä¾‹
# ============================================

_model_selector: Optional[ModelSelector] = None


def get_model_selector() -> ModelSelector:
    """è·å–å…¨å±€æ¨¡å‹é€‰æ‹©å™¨å•ä¾‹"""
    global _model_selector
    if _model_selector is None:
        _model_selector = ModelSelector()
    return _model_selector


def select_model_for_kernel(kernel_mode: str, override_model: Optional[str] = None) -> str:
    """
    ä¸ºå†…æ ¸é€‰æ‹©æ¨¡å‹ï¼ˆä¾¿æ·å‡½æ•°ï¼‰

    Args:
        kernel_mode: å†…æ ¸æ¨¡å¼å­—ç¬¦ä¸²ï¼ˆ"xml", "vision", "auto"ç­‰ï¼‰
        override_model: å¼ºåˆ¶æŒ‡å®šçš„æ¨¡å‹

    Returns:
        æ¨¡å‹åç§°

    Example:
        >>> model = select_model_for_kernel("xml")
        >>> print(model)  # glm-4.1v-thinking-flash
    """
    selector = get_model_selector()

    # è½¬æ¢å­—ç¬¦ä¸²ä¸ºæšä¸¾
    try:
        kernel_type = KernelType(kernel_mode.lower())
    except ValueError:
        logger.warning(f"æœªçŸ¥å†…æ ¸æ¨¡å¼: {kernel_mode}ï¼Œä½¿ç”¨AUTO")
        kernel_type = KernelType.AUTO

    return selector.select_model(kernel_type, override_model)


# ============================================
# Task Complexity Evaluation (Phase 3)
# ============================================


def evaluate_task_complexity(instruction: str) -> str:
    """
    Evaluate task complexity and return recommended model tier.

    Args:
        instruction: User instruction text

    Returns:
        "simple" or "complex"

    Simple tasks (use glm-4.6v-flash):
    - Single-step operations (open app, go back, screenshot)
    - Short instructions (< 20 chars)
    - Common app operations

    Complex tasks (use glm-4.6v):
    - Multi-step operations (with ç„¶å, å¹¶ä¸”, and, then)
    - Long instructions (> 50 chars)
    - Search/purchase/form-filling operations
    """
    instruction = instruction.strip().lower()

    # Check for complexity indicators
    complex_patterns = [
        "ç„¶å",
        "æ¥ç€",
        "ä¹‹å",
        "å¹¶ä¸”",
        "åŒæ—¶",
        "and then",
        "after that",
        "æœç´¢",
        "æŸ¥æ‰¾",
        "è´­ä¹°",
        "ä¸‹å•",
        "å¡«å†™",
        "è¾“å…¥",
        "å‘é€",
        "åˆ†æ",
    ]

    # Simple if short and no complex patterns
    if len(instruction) < 20:
        for pattern in complex_patterns:
            if pattern in instruction:
                return "complex"
        return "simple"

    # Complex if long or contains complex patterns
    if len(instruction) > 50:
        return "complex"

    for pattern in complex_patterns:
        if pattern in instruction:
            return "complex"

    return "simple"


def select_model_by_complexity(
    instruction: str,
    kernel_mode: str = "vision",
    override_model: Optional[str] = None,
) -> str:
    """
    Select model based on task complexity for cost optimization.

    Args:
        instruction: User instruction
        kernel_mode: Kernel mode string
        override_model: Force specific model

    Returns:
        Model name optimized for cost/performance
    """
    if override_model:
        return override_model

    complexity = evaluate_task_complexity(instruction)

    if complexity == "simple":
        # Use free/cheap model for simple tasks
        logger.info(f"Task complexity: simple â†’ using glm-4.6v-flash")
        return "glm-4.6v-flash"
    else:
        # Use standard model for complex tasks
        logger.info(f"Task complexity: complex â†’ using autoglm-phone")
        return "autoglm-phone"


# ============================================
# CLIå·¥å…·ï¼ˆç”¨äºæµ‹è¯•å’Œé…ç½®ï¼‰
# ============================================

if __name__ == "__main__":

    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format="%(levelname)s - %(message)s")

    print("\n" + "=" * 60)
    print("ğŸ“± PhoneAgent æ¨¡å‹é€‰æ‹©å™¨")
    print("=" * 60 + "\n")

    selector = ModelSelector()

    print("ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨:\n")
    for name, preset in selector.list_available_models().items():
        print(f"  â€¢ {preset}")
        print(f"    æè¿°: {preset.description}")
        print(f"    æ¨è: {', '.join(preset.recommended_for)}")
        print()

    print("=" * 60)
    print("ğŸ¯ å½“å‰ç­–ç•¥æµ‹è¯•:\n")

    test_cases = [
        ("xml", "XMLå†…æ ¸ï¼ˆé•¿ä»»åŠ¡ï¼Œéœ€è¦å¤§ä¸Šä¸‹æ–‡ï¼‰"),
        ("vision", "Visionå†…æ ¸ï¼ˆè§†è§‰ç†è§£ï¼‰"),
        ("planning", "è§„åˆ’æ¨¡å¼"),
        ("auto", "è‡ªåŠ¨æ¨¡å¼"),
    ]

    for kernel_mode, description in test_cases:
        model = select_model_for_kernel(kernel_mode)
        preset = selector.get_model_info(model)
        print(f"  â€¢ {description}")
        print(f"    å†…æ ¸: {kernel_mode}")
        print(f"    æ¨¡å‹: {preset if preset else model}")
        print()

    print("=" * 60)
    print("æç¤º:")
    print("  1. è®¾ç½® FORCE_SINGLE_MODEL=glm-4.1v-thinking-flash ç»Ÿä¸€ä½¿ç”¨å¤§æ¨¡å‹")
    print("  2. è®¾ç½® XML_KERNEL_MODEL=xxx å•ç‹¬é…ç½®XMLå†…æ ¸æ¨¡å‹")
    print("  3. è®¾ç½® VISION_KERNEL_MODEL=xxx å•ç‹¬é…ç½®Visionå†…æ ¸æ¨¡å‹")
    print("=" * 60 + "\n")
