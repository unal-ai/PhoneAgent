"""
æ¨¡å‹è°ƒç”¨è¿½è¸ªå™¨

åœ¨Agentæ‰§è¡Œè¿‡ç¨‹ä¸­è‡ªåŠ¨è®°å½•æ¨¡å‹è°ƒç”¨ç»Ÿè®¡
"""

import logging
from typing import Dict, Optional

from server.database import crud, get_db

logger = logging.getLogger(__name__)


class ModelCallTracker:
    """æ¨¡å‹è°ƒç”¨è¿½è¸ªå™¨"""

    @staticmethod
    async def track_call(
        task_id: str,
        model_name: str,
        kernel_mode: str,
        usage: Dict[str, int],
        latency_ms: int,
        provider: str = "zhipu",
        success: bool = True,
        error_message: Optional[str] = None,
    ):
        """
        è®°å½•æ¨¡å‹è°ƒç”¨

        Args:
            task_id: ä»»åŠ¡ID
            model_name: æ¨¡å‹åç§°
            kernel_mode: å†…æ ¸æ¨¡å¼ (xml/vision/auto)
            usage: Tokenä½¿ç”¨æƒ…å†µ {"prompt_tokens": 100, "completion_tokens": 50}
            latency_ms: å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
            provider: æä¾›å•†
            success: æ˜¯å¦æˆåŠŸ
            error_message: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        try:
            import asyncio

            def _record():
                db = next(get_db())
                try:
                    # è®¡ç®—æˆæœ¬ï¼ˆæ™ºè°±AIå®šä»·ï¼Œå¯é…ç½®ï¼‰
                    cost_usd = ModelCallTracker._calculate_cost(
                        model_name, usage.get("prompt_tokens", 0), usage.get("completion_tokens", 0)
                    )

                    crud.create_model_call(
                        db,
                        task_id=task_id,
                        provider=provider,
                        model_name=model_name,
                        kernel_mode=kernel_mode,
                        prompt_tokens=usage.get("prompt_tokens", 0),
                        completion_tokens=usage.get("completion_tokens", 0),
                        latency_ms=latency_ms,
                        cost_usd=cost_usd,
                        success=success,
                        error_message=error_message,
                    )

                    logger.debug(
                        f"ğŸ“Š Model call tracked: {model_name} | "
                        f"{usage.get('total_tokens', 0)} tokens | "
                        f"${cost_usd:.4f}"
                    )
                finally:
                    db.close()

            # å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»æµç¨‹
            await asyncio.get_event_loop().run_in_executor(None, _record)

        except Exception as e:
            # è®°å½•å¤±è´¥ä¸åº”å½±å“ä¸»æµç¨‹
            logger.error(f"Failed to track model call: {e}")

    @staticmethod
    def _calculate_cost(model_name: str, prompt_tokens: int, completion_tokens: int) -> float:
        """
        è®¡ç®—æˆæœ¬ï¼ˆç¾å…ƒï¼‰

        æ™ºè°±AIå®šä»·ï¼ˆ2025å¹´ï¼‰:
        - GLM-4.6V-FlashX: å…è´¹
        - glm-4-1.5v-thinking-flash: å…è´¹
        - autoglm-phone: å…è´¹

        æœªæ¥å¯æ‰©å±•ä¸ºä»˜è´¹æ¨¡å‹å®šä»·
        """
        # å½“å‰æ‰€æœ‰æ¨¡å‹å…è´¹
        if "flash" in model_name.lower() or "autoglm" in model_name.lower():
            return 0.0

        # é¢„ç•™ä»˜è´¹æ¨¡å‹å®šä»·ï¼ˆç¤ºä¾‹ï¼‰
        pricing = {
            "glm-4-plus": {"prompt": 0.05 / 1000, "completion": 0.05 / 1000},  # $0.05 per 1K tokens
            "glm-4-air": {"prompt": 0.001 / 1000, "completion": 0.001 / 1000},
        }

        if model_name in pricing:
            cost = (
                prompt_tokens * pricing[model_name]["prompt"]
                + completion_tokens * pricing[model_name]["completion"]
            )
            return round(cost, 6)

        return 0.0


# ä¾¿æ·å‡½æ•°
async def track_model_call(
    task_id: str,
    model_name: str,
    kernel_mode: str,
    usage: Dict[str, int],
    latency_ms: int,
    **kwargs,
):
    """ä¾¿æ·çš„æ¨¡å‹è°ƒç”¨è¿½è¸ªå‡½æ•°"""
    await ModelCallTracker.track_call(
        task_id=task_id,
        model_name=model_name,
        kernel_mode=kernel_mode,
        usage=usage,
        latency_ms=latency_ms,
        **kwargs,
    )
