#!/usr/bin/env python3
"""
æ™ºè°±AI HTTPå®¢æˆ·ç«¯
ç»Ÿä¸€å°è£…æ‰€æœ‰æ™ºè°±AI APIè°ƒç”¨ï¼Œä½¿ç”¨HTTPæ–¹å¼è€ŒéSDK

å®˜æ–¹æ–‡æ¡£: https://docs.bigmodel.cn/cn/api/introduction
APIç«¯ç‚¹: https://open.bigmodel.cn/api/paas/v4
"""

import json
import logging
from pathlib import Path
from typing import Any, AsyncIterator, Dict, Optional, Union

import httpx

logger = logging.getLogger(__name__)


class ZhipuAIClient:
    """
    æ™ºè°±AI HTTPå®¢æˆ·ç«¯

    ç»Ÿä¸€ä½¿ç”¨HTTP APIè°ƒç”¨æ‰€æœ‰æ™ºè°±AIæœåŠ¡ï¼š
    - å¯¹è¯è¡¥å…¨ï¼ˆChat Completionsï¼‰
    - è¯­éŸ³è½¬æ–‡å­—ï¼ˆSTTï¼‰
    - æ–‡å­—è½¬è¯­éŸ³ï¼ˆTTSï¼‰
    - å›¾åƒç”Ÿæˆ
    - æ–‡æœ¬åµŒå…¥
    """

    def __init__(
        self,
        api_key: str,
        base_url: str = "https://open.bigmodel.cn/api/paas/v4",
        timeout: float = 300.0,
    ):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯

        Args:
            api_key: æ™ºè°±AI APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.api_key = api_key
        self.base_url = base_url.rstrip("/")
        self.timeout = timeout

        # åˆ›å»ºHTTPå®¢æˆ·ç«¯
        self.client = httpx.AsyncClient(timeout=httpx.Timeout(timeout), headers=self._get_headers())

    def _get_headers(self, content_type: str = "application/json") -> Dict[str, str]:
        """è·å–è¯·æ±‚å¤´"""
        return {"Authorization": f"Bearer {self.api_key}", "Content-Type": content_type}

    async def close(self):
        """å…³é—­HTTPå®¢æˆ·ç«¯"""
        await self.client.aclose()

    # ============================================
    # å¯¹è¯è¡¥å…¨ï¼ˆChat Completionsï¼‰
    # ============================================

    async def chat_completions(
        self,
        model: str,
        messages: list,
        stream: bool = False,
        temperature: float = 0.7,
        top_p: float = 0.9,
        max_tokens: Optional[int] = None,
        **kwargs,
    ) -> Union[Dict[str, Any], AsyncIterator[str]]:
        """
        å¯¹è¯è¡¥å…¨

        Args:
            model: æ¨¡å‹åç§°ï¼Œå¦‚ "glm-4.6", "autoglm-phone"
            messages: æ¶ˆæ¯åˆ—è¡¨ [{"role": "user", "content": "hello"}]
            stream: æ˜¯å¦æµå¼è¾“å‡º
            temperature: æ¸©åº¦å‚æ•° (0.0-1.0)
            top_p: Top-pé‡‡æ ·
            max_tokens: æœ€å¤§tokenæ•°
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆtools, tool_choiceç­‰ï¼‰

        Returns:
            éæµå¼: å®Œæ•´å“åº”å­—å…¸
            æµå¼: å¼‚æ­¥ç”Ÿæˆå™¨ï¼Œyield æ¯ä¸ªchunkçš„æ–‡æœ¬

        APIæ–‡æ¡£: https://docs.bigmodel.cn/cn/api/chat/completions
        """
        url = f"{self.base_url}/chat/completions"

        payload = {
            "model": model,
            "messages": messages,
            "stream": stream,
            "temperature": temperature,
            "top_p": top_p,
        }

        if max_tokens:
            payload["max_tokens"] = max_tokens

        # æ·»åŠ å…¶ä»–å‚æ•°
        payload.update(kwargs)

        if stream:
            # æµå¼è¾“å‡º
            return self._stream_chat(url, payload)
        else:
            # éæµå¼è¾“å‡º
            response = await self.client.post(url, json=payload)
            response.raise_for_status()
            return response.json()

    async def _stream_chat(self, url: str, payload: Dict) -> AsyncIterator[str]:
        """
        æµå¼å¯¹è¯ç”Ÿæˆå™¨

        Yields:
            æ¯ä¸ªchunkçš„æ–‡æœ¬å†…å®¹
        """
        async with self.client.stream("POST", url, json=payload) as response:
            response.raise_for_status()

            async for line in response.aiter_lines():
                if not line or line.startswith(":"):
                    continue

                # SSEæ ¼å¼: "data: {...}"
                if line.startswith("data: "):
                    data_str = line[6:]  # å»æ‰ "data: "

                    if data_str == "[DONE]":
                        break

                    try:
                        data = json.loads(data_str)

                        # æå–content
                        if "choices" in data and len(data["choices"]) > 0:
                            choice = data["choices"][0]

                            # æµå¼å“åº”ä¸­æ˜¯delta
                            if "delta" in choice and "content" in choice["delta"]:
                                content = choice["delta"]["content"]
                                if content:
                                    yield content
                    except json.JSONDecodeError as e:
                        logger.warning(f"Failed to parse SSE data: {data_str}, error: {e}")
                        continue

    # ============================================
    # è¯­éŸ³è½¬æ–‡å­—ï¼ˆSTTï¼‰
    # ============================================

    async def audio_transcriptions(
        self,
        audio_file: Union[bytes, Path, str],
        model: str = "glm-asr-2512",
        filename: str = "audio.mp3",
        prompt: Optional[str] = None,
        stream: bool = False,
    ) -> Dict[str, Any]:
        """
        è¯­éŸ³è½¬æ–‡å­—ï¼ˆSpeech-to-Textï¼‰

        å®˜æ–¹APIæ–‡æ¡£: https://docs.bigmodel.cn/api-reference/æ¨¡å‹-api/è¯­éŸ³è½¬æ–‡æœ¬

        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶ï¼ˆbytesã€æ–‡ä»¶è·¯å¾„ï¼‰
                - æ”¯æŒæ ¼å¼: .wav / .mp3
                - æ–‡ä»¶å¤§å°: â‰¤ 25 MB
                - éŸ³é¢‘æ—¶é•¿: â‰¤ 30 ç§’
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ "glm-asr-2512"
            filename: æ–‡ä»¶åï¼ˆå½“audio_fileæ˜¯bytesæ—¶ä½¿ç”¨ï¼‰
            prompt: ä¸Šä¸‹æ–‡æç¤ºè¯ï¼Œç”¨äºé•¿æ–‡æœ¬åœºæ™¯ï¼ˆå»ºè®® < 8000å­—ï¼‰
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆé»˜è®¤Falseï¼‰

        Returns:
            {
                "text": "è¯†åˆ«çš„æ–‡æœ¬å†…å®¹",
                "model": "glm-asr-2512",
                "id": "ä»»åŠ¡ID",
                "created": 1234567890
            }

        å®Œæ•´curlç¤ºä¾‹:
            curl -X POST "https://open.bigmodel.cn/api/paas/v4/audio/transcriptions" \\
              -H "Authorization: Bearer YOUR_API_KEY" \\
              -F "file=@audio.mp3" \\
              -F "model=glm-asr-2512" \\
              -F "prompt=ä¸Šä¸‹æ–‡æç¤º"
        """
        url = f"{self.base_url}/audio/transcriptions"

        # å‡†å¤‡æ–‡ä»¶ï¼ˆmultipart/form-dataï¼‰
        import mimetypes

        if isinstance(audio_file, bytes):
            # ä»filenameæ¨æ–­MIMEç±»å‹
            mime_type = mimetypes.guess_type(filename)[0] or "audio/mpeg"
            logger.debug(
                f"STT: filename={filename}, size={len(audio_file)} bytes, mime={mime_type}"
            )
            files = {"file": (filename, audio_file, mime_type)}

        elif isinstance(audio_file, (str, Path)):
            audio_path = Path(audio_file)
            mime_type = mimetypes.guess_type(str(audio_path))[0] or "audio/mpeg"

            with open(audio_file, "rb") as f:
                audio_data = f.read()

            logger.debug(
                f"STT: file={audio_path.name}, size={len(audio_data)} bytes, mime={mime_type}"
            )
            files = {"file": (audio_path.name, audio_data, mime_type)}

        else:
            raise ValueError(f"Unsupported audio_file type: {type(audio_file)}")

        # æ„å»ºè¡¨å•æ•°æ®ï¼ˆmultipart/form-dataï¼‰
        data = {"model": model, "stream": "true" if stream else "false"}

        # æ·»åŠ å¯é€‰å‚æ•°
        if prompt:
            if len(prompt) > 8000:
                logger.warning(f"Prompt too long ({len(prompt)} chars), truncating to 8000")
                prompt = prompt[:8000]
            data["prompt"] = prompt
            logger.debug(f"ä½¿ç”¨ä¸Šä¸‹æ–‡æç¤ºè¯: {prompt[:50]}...")

        logger.info(
            f"ğŸ¤ Zhipu STT: model={model}, stream={stream}, prompt={'yes' if prompt else 'no'}"
        )
        logger.debug(f"ğŸ¤ Request URL: {url}")

        # è°ƒç”¨API
        try:
            # åˆ›å»ºç‹¬ç«‹çš„clientï¼Œç¡®ä¿multipart/form-dataæ­£ç¡®ç¼–ç 
            async with httpx.AsyncClient(timeout=httpx.Timeout(60.0)) as client:
                response = await client.post(
                    url, headers={"Authorization": f"Bearer {self.api_key}"}, files=files, data=data
                )

                response.raise_for_status()
                result = response.json()

                logger.info(f"STT Success: text_length={len(result.get('text', ''))}")
                return result

        except httpx.HTTPStatusError as e:
            error_detail = e.response.text if hasattr(e, "response") else str(e)
            logger.error(f"Zhipu STT Error: status={e.response.status_code}")
            logger.error(f"Detail: {error_detail}")
            logger.error(
                f"Request data: model={model}, stream={stream}, prompt_len={len(prompt) if prompt else 0}"
            )
            raise
        except Exception as e:
            logger.error(f"Unexpected STT error: {e}", exc_info=True)
            raise

    # ============================================
    # æ–‡å­—è½¬è¯­éŸ³ï¼ˆTTSï¼‰
    # ============================================

    async def audio_speech(
        self,
        text: str,
        model: str = "glm-tts",
        voice: str = "tongtong",
        speed: float = 1.0,
        volume: float = 1.0,
        response_format: str = "wav",
        stream: bool = False,
        watermark_enabled: bool = True,
    ) -> bytes:
        """
        æ–‡å­—è½¬è¯­éŸ³ï¼ˆéæµå¼ï¼‰

        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬ï¼ˆâ‰¤1024å­—ç¬¦ï¼‰
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ "glm-tts"
            voice: éŸ³è‰²é€‰æ‹©
                - tongtong: å½¤å½¤ï¼ˆé»˜è®¤ï¼‰
                - chuichui: é”¤é”¤
                - xiaochen: å°é™ˆ
                - jam/kazi/douji/luodo: åŠ¨åŠ¨åŠ¨ç‰©åœˆç³»åˆ—
            speed: è¯­é€Ÿï¼ŒèŒƒå›´ 0.5-2.0ï¼Œé»˜è®¤ 1.0
            volume: éŸ³é‡ï¼ŒèŒƒå›´ 0-10ï¼Œé»˜è®¤ 1.0
            response_format: è¾“å‡ºæ ¼å¼ï¼Œ"wav" æˆ– "pcm"
            stream: æ˜¯å¦æµå¼è¾“å‡ºï¼ˆæ­¤æ–¹æ³•å›ºå®šä¸ºFalseï¼‰
            watermark_enabled: æ˜¯å¦æ·»åŠ AIç”Ÿæˆæ°´å°

        Returns:
            éŸ³é¢‘æ–‡ä»¶çš„äºŒè¿›åˆ¶æ•°æ®

        APIæ–‡æ¡£: https://docs.bigmodel.cn/api-reference/æ¨¡å‹-api/æ–‡æœ¬è½¬è¯­éŸ³
        """
        url = f"{self.base_url}/audio/speech"

        # æ£€æŸ¥æ–‡æœ¬é•¿åº¦
        if len(text) > 1024:
            logger.warning(f"Text too long: {len(text)} chars, truncating to 1024")
            text = text[:1024]

        payload = {
            "model": model,
            "input": text,  # å®˜æ–¹æ–‡æ¡£ä½¿ç”¨ input å­—æ®µ
            "voice": voice,
            "speed": max(0.5, min(2.0, speed)),  # é™åˆ¶èŒƒå›´ [0.5, 2]
            "volume": max(0.0, min(10.0, volume)),  # é™åˆ¶èŒƒå›´ (0, 10]
            "response_format": response_format,  # wav æˆ– pcm
            "stream": False,
            "watermark_enabled": watermark_enabled,
        }

        logger.info(
            f"Calling Zhipu TTS API: voice={voice}, text_len={len(text)}, format={response_format}"
        )

        response = await self.client.post(url, json=payload)
        response.raise_for_status()

        # è¿”å›äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
        return response.content

    async def audio_speech_stream(
        self,
        text: str,
        model: str = "glm-tts",
        voice: str = "tongtong",
        speed: float = 1.0,
        volume: float = 1.0,
        encode_format: str = "base64",
        watermark_enabled: bool = True,
    ) -> AsyncIterator[bytes]:
        """
        æµå¼æ–‡å­—è½¬è¯­éŸ³

        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬ï¼ˆâ‰¤1024å­—ç¬¦ï¼‰
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ "glm-tts"
            voice: éŸ³è‰²é€‰æ‹©ï¼ˆåŒaudio_speechï¼‰
            speed: è¯­é€Ÿï¼ŒèŒƒå›´ 0.5-2.0
            volume: éŸ³é‡ï¼ŒèŒƒå›´ 0-10
            encode_format: ç¼–ç æ ¼å¼ï¼Œ"base64" æˆ– "hex"
            watermark_enabled: æ˜¯å¦æ·»åŠ AIç”Ÿæˆæ°´å°

        Yields:
            éŸ³é¢‘æ•°æ®å—ï¼ˆPCMæ ¼å¼ï¼‰

        æ³¨æ„: æµå¼è¾“å‡ºä»…æ”¯æŒPCMæ ¼å¼
        """
        url = f"{self.base_url}/audio/speech"

        # æ£€æŸ¥æ–‡æœ¬é•¿åº¦
        if len(text) > 1024:
            logger.warning(f"Text too long: {len(text)} chars, truncating to 1024")
            text = text[:1024]

        payload = {
            "model": model,
            "input": text,
            "voice": voice,
            "speed": max(0.5, min(2.0, speed)),
            "volume": max(0.0, min(10.0, volume)),
            "response_format": "pcm",  # æµå¼ä»…æ”¯æŒpcm
            "stream": True,
            "encode_format": encode_format,
            "watermark_enabled": watermark_enabled,
        }

        logger.info(f"Calling Zhipu TTS Stream API: voice={voice}, text_len={len(text)}")

        async with self.client.stream("POST", url, json=payload) as response:
            response.raise_for_status()

            async for chunk in response.aiter_bytes(chunk_size=1024):
                if chunk:
                    yield chunk

    # ============================================
    # å›¾åƒç”Ÿæˆ
    # ============================================

    async def images_generations(
        self, prompt: str, model: str = "cogview-3", size: str = "1024x1024", n: int = 1
    ) -> Dict[str, Any]:
        """
        å›¾åƒç”Ÿæˆ

        Args:
            prompt: å›¾åƒæè¿°æç¤ºè¯
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ "cogview-3"
            size: å›¾åƒå°ºå¯¸ï¼Œå¦‚ "1024x1024"
            n: ç”Ÿæˆå›¾åƒæ•°é‡

        Returns:
            {
                "data": [
                    {
                        "url": "å›¾åƒURL",
                        "b64_json": "base64ç¼–ç çš„å›¾åƒ"
                    }
                ],
                ...
            }

        APIæ–‡æ¡£: https://docs.bigmodel.cn/cn/api/images/generations
        """
        url = f"{self.base_url}/images/generations"

        payload = {"model": model, "prompt": prompt, "size": size, "n": n}

        response = await self.client.post(url, json=payload)
        response.raise_for_status()
        return response.json()

    # ============================================
    # æ–‡æœ¬åµŒå…¥ï¼ˆEmbeddingsï¼‰
    # ============================================

    async def embeddings(
        self, input_text: Union[str, list], model: str = "embedding-2"
    ) -> Dict[str, Any]:
        """
        æ–‡æœ¬åµŒå…¥

        Args:
            input_text: è¾“å…¥æ–‡æœ¬ï¼ˆå­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ "embedding-2"

        Returns:
            {
                "data": [
                    {
                        "embedding": [0.1, 0.2, ...],
                        "index": 0
                    }
                ],
                "model": "embedding-2",
                ...
            }

        APIæ–‡æ¡£: https://docs.bigmodel.cn/cn/api/embeddings
        """
        url = f"{self.base_url}/embeddings"

        payload = {"model": model, "input": input_text}

        response = await self.client.post(url, json=payload)
        response.raise_for_status()
        return response.json()


# ============================================
# ä¾¿æ·å‡½æ•°
# ============================================


def get_zhipu_client(api_key: str) -> ZhipuAIClient:
    """
    è·å–æ™ºè°±AIå®¢æˆ·ç«¯å®ä¾‹

    Args:
        api_key: APIå¯†é’¥

    Returns:
        ZhipuAIClientå®ä¾‹
    """
    return ZhipuAIClient(api_key=api_key)


# ============================================
# ä½¿ç”¨ç¤ºä¾‹
# ============================================

"""
# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = ZhipuAIClient(api_key="your_api_key")

# 1. å¯¹è¯è¡¥å…¨ï¼ˆéæµå¼ï¼‰
response = await client.chat_completions(
    model="autoglm-phone",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹"},
        {"role": "user", "content": "ä½ å¥½"}
    ]
)
print(response['choices'][0]['message']['content'])

# 2. å¯¹è¯è¡¥å…¨ï¼ˆæµå¼ï¼‰
async for text in await client.chat_completions(
    model="glm-4.6",
    messages=[{"role": "user", "content": "è®²ä¸ªæ•…äº‹"}],
    stream=True
):
    print(text, end='', flush=True)

# 3. è¯­éŸ³è½¬æ–‡å­—
result = await client.audio_transcriptions(
    audio_file="audio.wav"
)
print(result['text'])

# 4. æ–‡å­—è½¬è¯­éŸ³
audio_data = await client.audio_speech(
    text="ä½ å¥½ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹",
    voice="female"
)
with open("output.mp3", "wb") as f:
    f.write(audio_data)

# 5. æ–‡å­—è½¬è¯­éŸ³ï¼ˆæµå¼ï¼‰
with open("output.mp3", "wb") as f:
    async for chunk in await client.audio_speech_stream(
        text="è¿™æ˜¯ä¸€æ®µè¾ƒé•¿çš„æ–‡æœ¬..."
    ):
        f.write(chunk)

# 6. å›¾åƒç”Ÿæˆ
result = await client.images_generations(
    prompt="ä¸€åªå¯çˆ±çš„çŒ«"
)
print(result['data'][0]['url'])

# 7. æ–‡æœ¬åµŒå…¥
result = await client.embeddings(
    input_text="è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬"
)
print(result['data'][0]['embedding'][:5])

# å…³é—­å®¢æˆ·ç«¯
await client.close()
"""
